{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HoohemEh1G8",
        "outputId": "eb2af134-e630-4d0c-96fc-f6f328d24955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37, 3)\n",
            "(37, 2)\n",
            "(3, 3)\n",
            "(3, 2)\n",
            "(10, 3)\n",
            "(10, 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a dataframe with random values\n",
        "df = pd.DataFrame(np.random.randint(0, 100, size=(50, 5)), columns=['temp', 'hum', 'soil', 'ldr', 'carbon'])\n",
        "\n",
        "# Split the data into input and output\n",
        "input_data = df[['temp', 'hum', 'carbon']]\n",
        "output_data = df[['soil', 'ldr']]\n",
        "\n",
        "# Apply standardization to the input and output data\n",
        "scaler = StandardScaler()\n",
        "input_data_scaled = scaler.fit_transform(input_data)\n",
        "output_data_scaled = scaler.fit_transform(output_data)\n",
        "\n",
        "# Split the data into training, validation, and testing data\n",
        "input_train, input_test, output_train, output_test = train_test_split(input_data_scaled, output_data_scaled, test_size=0.05, random_state=0)\n",
        "input_train, input_val, output_train, output_val = train_test_split(input_train, output_train, test_size=0.2, random_state=0)\n",
        "print(input_train.shape)\n",
        "print(output_train.shape)\n",
        "print(input_test.shape)\n",
        "print(output_test.shape)\n",
        "print(input_val.shape)\n",
        "print(output_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a model using the Dense layer\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=32, input_shape=(3,), activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=2, activation='relu'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eMm5WZEiER4",
        "outputId": "389fcb64-df1b-4152-f177-0d34a7dde4f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 32)                128       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,370\n",
            "Trainable params: 2,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(input_train, output_train, epochs=100, validation_data=(input_val, output_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_soOiLpkcDy",
        "outputId": "bfc66e8a-d689-4408-94ba-271768f42c0b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 178ms/step - loss: 0.9822 - val_loss: 1.3004\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9692 - val_loss: 1.2972\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.9636 - val_loss: 1.2965\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9596 - val_loss: 1.2950\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9564 - val_loss: 1.2933\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9536 - val_loss: 1.2911\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.9508 - val_loss: 1.2880\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9458 - val_loss: 1.2872\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9408 - val_loss: 1.2879\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.9356 - val_loss: 1.2889\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9312 - val_loss: 1.2910\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9296 - val_loss: 1.2925\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.9269 - val_loss: 1.2931\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.9238 - val_loss: 1.2935\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9207 - val_loss: 1.2941\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.9192 - val_loss: 1.2951\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9174 - val_loss: 1.2944\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9155 - val_loss: 1.2935\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9138 - val_loss: 1.2941\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9119 - val_loss: 1.2945\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.9105 - val_loss: 1.2939\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9087 - val_loss: 1.2936\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9076 - val_loss: 1.2938\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9068 - val_loss: 1.2941\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.9050 - val_loss: 1.2938\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9034 - val_loss: 1.2930\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.9029 - val_loss: 1.2939\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.9038 - val_loss: 1.2962\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.9018 - val_loss: 1.2990\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.9006 - val_loss: 1.3028\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8995 - val_loss: 1.3056\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8987 - val_loss: 1.3069\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8981 - val_loss: 1.3069\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8969 - val_loss: 1.3061\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8961 - val_loss: 1.3057\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8958 - val_loss: 1.3058\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8960 - val_loss: 1.3051\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8945 - val_loss: 1.3034\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8934 - val_loss: 1.3017\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8920 - val_loss: 1.3001\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8898 - val_loss: 1.2985\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8889 - val_loss: 1.2981\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8881 - val_loss: 1.2996\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8878 - val_loss: 1.3012\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8867 - val_loss: 1.3027\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8856 - val_loss: 1.3046\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8850 - val_loss: 1.3060\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.8844 - val_loss: 1.3073\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8836 - val_loss: 1.3097\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8835 - val_loss: 1.3116\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8830 - val_loss: 1.3128\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8824 - val_loss: 1.3128\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8815 - val_loss: 1.3119\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8805 - val_loss: 1.3113\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8795 - val_loss: 1.3122\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8787 - val_loss: 1.3134\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8775 - val_loss: 1.3139\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8768 - val_loss: 1.3139\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8758 - val_loss: 1.3126\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8759 - val_loss: 1.3123\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8771 - val_loss: 1.3121\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8771 - val_loss: 1.3119\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8766 - val_loss: 1.3120\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8758 - val_loss: 1.3103\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8738 - val_loss: 1.3083\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8722 - val_loss: 1.3075\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8709 - val_loss: 1.3064\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8697 - val_loss: 1.3059\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8700 - val_loss: 1.3078\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8682 - val_loss: 1.3116\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8687 - val_loss: 1.3156\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8699 - val_loss: 1.3186\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8692 - val_loss: 1.3201\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8690 - val_loss: 1.3203\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8664 - val_loss: 1.3168\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8649 - val_loss: 1.3111\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8628 - val_loss: 1.3082\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8618 - val_loss: 1.3061\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8608 - val_loss: 1.3044\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8608 - val_loss: 1.3019\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8617 - val_loss: 1.2997\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8625 - val_loss: 1.2976\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.8641 - val_loss: 1.2952\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8648 - val_loss: 1.2937\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8651 - val_loss: 1.2933\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8638 - val_loss: 1.2944\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8615 - val_loss: 1.2969\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8595 - val_loss: 1.3003\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8554 - val_loss: 1.3044\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8552 - val_loss: 1.3092\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8541 - val_loss: 1.3118\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8528 - val_loss: 1.3134\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8533 - val_loss: 1.3140\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8532 - val_loss: 1.3132\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8522 - val_loss: 1.3130\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8513 - val_loss: 1.3138\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8503 - val_loss: 1.3155\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.8496 - val_loss: 1.3195\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8507 - val_loss: 1.3244\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8510 - val_loss: 1.3285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f240666f2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model to make predictions with the testing data\n",
        "predictions = model.predict(input_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWtPfatGkwie",
        "outputId": "c36e8897-8189-4609-959d-5d2efde20bf3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 78ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inverse the standardization to the predictions\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions = pd.DataFrame(predictions, columns=['temp', 'hum'])\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "uOuxwXVtjpFN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new dataset\n",
        "new_data = np.random.rand(10, 3)\n",
        "# Standardize the new dataset\n",
        "mean = np.mean(new_data, axis=0)\n",
        "std = np.std(new_data, axis=0)\n",
        "new_data = (new_data - mean) / std\n",
        "\n",
        "# Make predictions using the model\n",
        "predictions = model.predict(new_data)\n",
        "predictions = pd.DataFrame(predictions, columns=['temp', 'hum'])\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umODZCFanP82",
        "outputId": "b1b2b42c-b825-49c9-b4e8-a0a537e0ed8b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "       temp       hum\n",
            "0  0.024052  0.312269\n",
            "1  0.312020  0.424663\n",
            "2  0.125484  0.000000\n",
            "3  0.097439  0.000000\n",
            "4  0.149380  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "2KkQtrblzcoX",
        "outputId": "12531ba3-2568-453e-be4c-a161a2c7a9eb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        temp       hum      soil\n",
              "0   0.617155  0.097313  0.632754\n",
              "1   0.497404  0.713998  0.176817\n",
              "2   0.265415  0.188900  0.289158\n",
              "3   0.173942  0.233893  0.408220\n",
              "4   0.671379  0.389024  0.672773\n",
              "5   0.856928  0.541624  0.002433\n",
              "6   0.946510  0.639363  0.759699\n",
              "7   0.006681  0.821683  0.680778\n",
              "8   0.536388  0.874523  0.159925\n",
              "9   0.544277  0.005906  0.271691\n",
              "10  0.244584  0.958031  0.068928\n",
              "11  0.735159  0.662066  0.775924\n",
              "12  0.253140  0.517214  0.432930\n",
              "13  0.691522  0.933138  0.196989\n",
              "14  0.369772  0.163225  0.168609"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b81f450-f7ca-4c0c-862c-08203c478ea6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp</th>\n",
              "      <th>hum</th>\n",
              "      <th>soil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.617155</td>\n",
              "      <td>0.097313</td>\n",
              "      <td>0.632754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.497404</td>\n",
              "      <td>0.713998</td>\n",
              "      <td>0.176817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.265415</td>\n",
              "      <td>0.188900</td>\n",
              "      <td>0.289158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.173942</td>\n",
              "      <td>0.233893</td>\n",
              "      <td>0.408220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.671379</td>\n",
              "      <td>0.389024</td>\n",
              "      <td>0.672773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.856928</td>\n",
              "      <td>0.541624</td>\n",
              "      <td>0.002433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.946510</td>\n",
              "      <td>0.639363</td>\n",
              "      <td>0.759699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.006681</td>\n",
              "      <td>0.821683</td>\n",
              "      <td>0.680778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.536388</td>\n",
              "      <td>0.874523</td>\n",
              "      <td>0.159925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.544277</td>\n",
              "      <td>0.005906</td>\n",
              "      <td>0.271691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.244584</td>\n",
              "      <td>0.958031</td>\n",
              "      <td>0.068928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.735159</td>\n",
              "      <td>0.662066</td>\n",
              "      <td>0.775924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.253140</td>\n",
              "      <td>0.517214</td>\n",
              "      <td>0.432930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.691522</td>\n",
              "      <td>0.933138</td>\n",
              "      <td>0.196989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.369772</td>\n",
              "      <td>0.163225</td>\n",
              "      <td>0.168609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b81f450-f7ca-4c0c-862c-08203c478ea6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b81f450-f7ca-4c0c-862c-08203c478ea6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b81f450-f7ca-4c0c-862c-08203c478ea6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new dataset\n",
        "new_data = np.random.rand(15, 3)\n",
        "# Make predictions using the model\n",
        "predictions = model.predict(new_data)\n",
        "predictions = pd.DataFrame(predictions, columns=['temp', 'hum'])\n",
        "new_data = pd.DataFrame(new_data, columns=['temp', 'hum', 'soil'])\n",
        "result_df = pd.concat([new_data, predictions], axis=1)\n",
        "print(result_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6cBkkXBn9nS",
        "outputId": "02ce5159-3530-4873-d98e-23fad832462c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "        temp       hum      soil      temp       hum\n",
            "0   0.617155  0.097313  0.632754  0.285977  0.059987\n",
            "1   0.497404  0.713998  0.176817  0.214914  0.143182\n",
            "2   0.265415  0.188900  0.289158  0.200022  0.163902\n",
            "3   0.173942  0.233893  0.408220  0.166791  0.268910\n",
            "4   0.671379  0.389024  0.672773  0.349937  0.143012\n",
            "5   0.856928  0.541624  0.002433  0.224756  0.000000\n",
            "6   0.946510  0.639363  0.759699  0.407969  0.096267\n",
            "7   0.006681  0.821683  0.680778  0.134054  0.649881\n",
            "8   0.536388  0.874523  0.159925  0.219140  0.173670\n",
            "9   0.544277  0.005906  0.271691  0.187248  0.000000\n",
            "10  0.244584  0.958031  0.068928  0.216029  0.352540\n",
            "11  0.735159  0.662066  0.775924  0.371717  0.234468\n",
            "12  0.253140  0.517214  0.432930  0.215172  0.337303\n",
            "13  0.691522  0.933138  0.196989  0.246450  0.094833\n",
            "14  0.369772  0.163225  0.168609  0.198915  0.041072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "udJHSXNmtIMV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reload the saved model\n",
        "loaded_model = tf.keras.models.load_model('model.h5')\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the converted model\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oTyrUp3tRO1",
        "outputId": "a974a57c-213e-4792-e896-7a312b23cca2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11340"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  tinymlgen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX_XaWqb3Kko",
        "outputId": "b09fa9b4-a6ec-4423-e2d4-dc4d13b65410"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tinymlgen\n",
            "  Downloading tinymlgen-0.2.tar.gz (1.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from tinymlgen) (2.9.2)\n",
            "Collecting hexdump\n",
            "  Downloading hexdump-3.3.zip (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.51.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (15.0.6.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.1.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (0.29.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (4.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->tinymlgen) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->tinymlgen) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (2.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->tinymlgen) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (5.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->tinymlgen) (3.2.2)\n",
            "Building wheels for collected packages: tinymlgen, hexdump\n",
            "  Building wheel for tinymlgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinymlgen: filename=tinymlgen-0.2-py3-none-any.whl size=2242 sha256=1aa6098e8d63a0ae8414c2b75bf206d0684f998d8d2695930d934b082016514d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/a1/f5/2884c682bcacd0a96875431737d5c792e8dd0a1e4e163512be\n",
            "  Building wheel for hexdump (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hexdump: filename=hexdump-3.3-py3-none-any.whl size=8913 sha256=f0055341539602a264f2d58d61f2d6d357fe1e1f7e986f2d53b9903875cf3d74\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/b7/72/1cc327e831ffef71bca1b0ca5e40b68471875f740ec9270c0f\n",
            "Successfully built tinymlgen hexdump\n",
            "Installing collected packages: hexdump, tinymlgen\n",
            "Successfully installed hexdump-3.3 tinymlgen-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_code = port(model, pretty_print=True)\n",
        "print(c_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0l2wh7n4Pkf",
        "outputId": "6837c155-187b-4339-f1c0-9f5ac4a11b28"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#ifdef __has_attribute\n",
            "#define HAVE_ATTRIBUTE(x) __has_attribute(x)\n",
            "#else\n",
            "#define HAVE_ATTRIBUTE(x) 0\n",
            "#endif\n",
            "#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))\n",
            "#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\n",
            "#else\n",
            "#define DATA_ALIGN_ATTRIBUTE\n",
            "#endif\n",
            "\n",
            "const unsigned char model_data[] DATA_ALIGN_ATTRIBUTE = {\n",
            "\t0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00, \n",
            "\t0x14, 0x00, 0x20, 0x00, 0x1c, 0x00, 0x18, 0x00, 0x14, 0x00, 0x10, 0x00, \n",
            "\t0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00, \n",
            "\t0x1c, 0x00, 0x00, 0x00, 0x94, 0x00, 0x00, 0x00, 0xec, 0x00, 0x00, 0x00, \n",
            "\t0x0c, 0x0f, 0x00, 0x00, 0x1c, 0x0f, 0x00, 0x00, 0x44, 0x14, 0x00, 0x00, \n",
            "\t0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, \n",
            "\t0x0a, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, \n",
            "\t0x38, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76, \n",
            "\t0x69, 0x6e, 0x67, 0x5f, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x00, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x94, 0xff, 0xff, 0xff, \n",
            "\t0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, \n",
            "\t0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x39, 0x00, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0x04, 0x00, 0x00, 0x00, 0x86, 0xf1, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x0d, 0x00, 0x00, 0x00, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x37, 0x5f, \n",
            "\t0x69, 0x6e, 0x70, 0x75, 0x74, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, \n",
            "\t0x34, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xdc, 0xff, 0xff, 0xff, \n",
            "\t0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, \n",
            "\t0x43, 0x4f, 0x4e, 0x56, 0x45, 0x52, 0x53, 0x49, 0x4f, 0x4e, 0x5f, 0x4d, \n",
            "\t0x45, 0x54, 0x41, 0x44, 0x41, 0x54, 0x41, 0x00, 0x08, 0x00, 0x0c, 0x00, \n",
            "\t0x08, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, \n",
            "\t0x04, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, 0x6d, 0x69, 0x6e, 0x5f, \n",
            "\t0x72, 0x75, 0x6e, 0x74, 0x69, 0x6d, 0x65, 0x5f, 0x76, 0x65, 0x72, 0x73, \n",
            "\t0x69, 0x6f, 0x6e, 0x00, 0x0d, 0x00, 0x00, 0x00, 0x1c, 0x0e, 0x00, 0x00, \n",
            "\t0x14, 0x0e, 0x00, 0x00, 0xfc, 0x0d, 0x00, 0x00, 0xe4, 0x0c, 0x00, 0x00, \n",
            "\t0x54, 0x0c, 0x00, 0x00, 0xc4, 0x0a, 0x00, 0x00, 0xb4, 0x08, 0x00, 0x00, \n",
            "\t0xa4, 0x00, 0x00, 0x00, 0x9c, 0x00, 0x00, 0x00, 0x94, 0x00, 0x00, 0x00, \n",
            "\t0x8c, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x36, 0xf2, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x58, 0x00, 0x00, 0x00, \n",
            "\t0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0e, 0x00, 0x08, 0x00, 0x04, 0x00, \n",
            "\t0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, \n",
            "\t0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xea, 0x03, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, \n",
            "\t0x0a, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, \n",
            "\t0x04, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x32, 0x2e, 0x39, 0x2e, \n",
            "\t0x32, 0x00, 0x00, 0x00, 0x9a, 0xf2, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x10, 0x00, 0x00, 0x00, 0x32, 0x2e, 0x33, 0x2e, 0x30, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x8c, 0xed, 0xff, 0xff, \n",
            "\t0x90, 0xed, 0xff, 0xff, 0x94, 0xed, 0xff, 0xff, 0xc2, 0xf2, 0xff, 0xff, \n",
            "\t0x04, 0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x1b, 0xdf, 0xd2, 0xcb, \n",
            "\t0xc4, 0x43, 0xda, 0x0c, 0x23, 0x3b, 0x13, 0x2d, 0x1d, 0x2a, 0x2a, 0xff, \n",
            "\t0x0e, 0x07, 0xe0, 0xb6, 0x03, 0x57, 0xe8, 0xec, 0xe7, 0xfb, 0x2e, 0x2c, \n",
            "\t0x09, 0xb9, 0xb4, 0x40, 0x4e, 0x2d, 0x24, 0x34, 0x31, 0xdd, 0x15, 0x2d, \n",
            "\t0xff, 0xae, 0x13, 0x2c, 0x35, 0xc2, 0xfa, 0x2f, 0xa6, 0xd5, 0x1d, 0x10, \n",
            "\t0xd1, 0xe6, 0x1e, 0xb3, 0x19, 0x46, 0x91, 0x92, 0xb7, 0xb0, 0x0c, 0xed, \n",
            "\t0x57, 0x44, 0x0b, 0x33, 0xff, 0x29, 0x06, 0xb6, 0x3c, 0xe0, 0xd9, 0xbc, \n",
            "\t0x40, 0x10, 0xf0, 0x31, 0xe8, 0x22, 0xc8, 0xff, 0x1b, 0xd5, 0x34, 0x31, \n",
            "\t0xf5, 0x2b, 0x4e, 0x35, 0x49, 0x03, 0x1d, 0xbf, 0xec, 0xea, 0x49, 0x2c, \n",
            "\t0x11, 0x24, 0x4e, 0x36, 0x20, 0x55, 0xc5, 0x4a, 0x41, 0xfb, 0xcc, 0xd1, \n",
            "\t0xbd, 0x51, 0x19, 0xf3, 0xde, 0xd0, 0xd6, 0xcf, 0xe2, 0xbe, 0x23, 0x2e, \n",
            "\t0x1a, 0x4e, 0xae, 0xf5, 0x54, 0x18, 0xf1, 0xba, 0xf6, 0xd3, 0x2b, 0x4a, \n",
            "\t0x47, 0xed, 0x32, 0x2a, 0xc8, 0x06, 0x38, 0xd4, 0x1a, 0xee, 0x5d, 0xab, \n",
            "\t0xc5, 0x34, 0x1c, 0xbd, 0xe7, 0xf5, 0x22, 0xa8, 0xc3, 0x0c, 0xf6, 0xf5, \n",
            "\t0xb7, 0xe5, 0x1d, 0x06, 0x14, 0x06, 0xf7, 0xa2, 0x40, 0x14, 0x3a, 0x52, \n",
            "\t0x0f, 0xf4, 0x06, 0xc4, 0x04, 0xd8, 0xa3, 0x41, 0xb9, 0xd0, 0xd5, 0x07, \n",
            "\t0x2a, 0x52, 0x24, 0x18, 0xad, 0xd3, 0x31, 0xde, 0xda, 0xd5, 0x19, 0x07, \n",
            "\t0x0f, 0xaf, 0x37, 0x3e, 0x19, 0x55, 0xe4, 0xd5, 0xf5, 0x23, 0xfa, 0x03, \n",
            "\t0x53, 0xfb, 0x4f, 0xbd, 0x56, 0xd5, 0xdd, 0xcc, 0xf3, 0x13, 0x02, 0x44, \n",
            "\t0x0c, 0x02, 0xb8, 0xe7, 0x61, 0x2a, 0x13, 0x19, 0x43, 0xa4, 0x18, 0xaf, \n",
            "\t0x1f, 0xfb, 0x29, 0xc8, 0xea, 0x01, 0xad, 0x33, 0x3a, 0xbe, 0x3c, 0xcd, \n",
            "\t0xc0, 0xd6, 0x3d, 0xcf, 0xf7, 0x17, 0x0c, 0xae, 0xb3, 0xb8, 0x53, 0xbe, \n",
            "\t0x18, 0x9c, 0x37, 0x9e, 0xcd, 0xc2, 0xd5, 0x14, 0x0f, 0xb6, 0xf8, 0x0a, \n",
            "\t0x0a, 0x35, 0x38, 0xff, 0x4f, 0xe9, 0x3e, 0xa9, 0xdd, 0x25, 0xd4, 0x2e, \n",
            "\t0x3f, 0xc2, 0x0d, 0xf9, 0xc3, 0x2e, 0xe8, 0xf8, 0x3f, 0xf3, 0x50, 0x1a, \n",
            "\t0x2c, 0x2e, 0x45, 0xd7, 0xc3, 0x09, 0x58, 0xf7, 0x58, 0x09, 0xb0, 0xdd, \n",
            "\t0x44, 0x37, 0x59, 0xb6, 0x40, 0x15, 0x58, 0xb4, 0x4e, 0x00, 0xfd, 0x1e, \n",
            "\t0x1b, 0xc2, 0x5e, 0xda, 0xf4, 0xd8, 0x45, 0xd7, 0xf0, 0x3c, 0x24, 0x0f, \n",
            "\t0xe1, 0xad, 0xd3, 0xcc, 0x35, 0x36, 0x3c, 0xf1, 0xc3, 0x16, 0xa5, 0x00, \n",
            "\t0xdd, 0x42, 0xbf, 0xe1, 0xc8, 0x5c, 0x2f, 0x23, 0xbb, 0xb8, 0x3b, 0xad, \n",
            "\t0x1c, 0x07, 0x1d, 0x3d, 0xf1, 0x47, 0x0a, 0xca, 0x12, 0x02, 0x45, 0x11, \n",
            "\t0x29, 0x4e, 0xe1, 0xc2, 0xd2, 0x2b, 0x03, 0xb6, 0x0b, 0xd0, 0x47, 0xe4, \n",
            "\t0xc5, 0xc8, 0x0f, 0x99, 0x2f, 0xe8, 0xba, 0x4f, 0xe0, 0x34, 0x25, 0xf2, \n",
            "\t0xcf, 0xdf, 0x19, 0x07, 0xc7, 0x51, 0xea, 0x18, 0x37, 0xa5, 0x47, 0x14, \n",
            "\t0x1b, 0xfd, 0xe3, 0x2c, 0x2f, 0x4c, 0x2b, 0x14, 0x4f, 0xc7, 0x44, 0x07, \n",
            "\t0xe5, 0xbe, 0xb8, 0xd2, 0xd2, 0xe1, 0xa7, 0x4d, 0x18, 0xfd, 0xdd, 0xcc, \n",
            "\t0x47, 0x13, 0xe1, 0xee, 0xe5, 0xc4, 0xe4, 0x3a, 0xbb, 0xce, 0xf7, 0xcf, \n",
            "\t0x4f, 0x4f, 0x37, 0x58, 0x28, 0x99, 0xc6, 0x49, 0xbd, 0x4e, 0x40, 0x51, \n",
            "\t0x9d, 0x51, 0xcd, 0xbf, 0x39, 0x4d, 0xe7, 0x1b, 0xb3, 0xe5, 0x06, 0x49, \n",
            "\t0x21, 0x15, 0x2c, 0xb6, 0xf5, 0x49, 0xeb, 0x55, 0xbc, 0x95, 0xea, 0xa4, \n",
            "\t0x90, 0x05, 0x51, 0xaf, 0x3f, 0xde, 0x31, 0x27, 0x17, 0x43, 0x1a, 0xb9, \n",
            "\t0xde, 0x00, 0xa6, 0x00, 0xec, 0x10, 0xfa, 0xbb, 0x4e, 0xc4, 0x0a, 0xb6, \n",
            "\t0x4b, 0xbb, 0xfc, 0x40, 0xa6, 0xbb, 0x2b, 0xbb, 0xe7, 0xc5, 0xc0, 0xb1, \n",
            "\t0xda, 0xbb, 0x0f, 0x2e, 0x5a, 0xcc, 0x42, 0x35, 0x4a, 0xbc, 0x0e, 0xb5, \n",
            "\t0xe4, 0xf1, 0x15, 0xc7, 0xb1, 0xe2, 0xbd, 0xc3, 0xf7, 0xc7, 0x32, 0xc7, \n",
            "\t0x2f, 0xb1, 0x01, 0x86, 0xf4, 0x00, 0x2e, 0x0d, 0xfe, 0xd0, 0x4a, 0xb5, \n",
            "\t0x0e, 0x43, 0xf9, 0xbe, 0xba, 0x2b, 0x31, 0x28, 0x0c, 0x99, 0xa0, 0x1e, \n",
            "\t0xd6, 0xb1, 0xd9, 0xe2, 0x46, 0xd1, 0x0b, 0x2b, 0xa3, 0xe4, 0x01, 0xb8, \n",
            "\t0x37, 0x00, 0x34, 0x1f, 0x10, 0x30, 0x5c, 0x2d, 0x49, 0xe3, 0xd8, 0x3d, \n",
            "\t0x29, 0x0b, 0x21, 0x10, 0xc8, 0x27, 0x2a, 0xba, 0x53, 0x24, 0xce, 0xd4, \n",
            "\t0xae, 0xd4, 0x24, 0xbd, 0x46, 0x9f, 0x02, 0xda, 0x14, 0x07, 0x81, 0x00, \n",
            "\t0xfb, 0x3a, 0x2b, 0xf5, 0xdc, 0x59, 0x33, 0xf4, 0xf1, 0xbf, 0xc9, 0x38, \n",
            "\t0x21, 0xea, 0xe0, 0xb9, 0x25, 0xed, 0xcf, 0xfa, 0xf9, 0x53, 0x3e, 0x3d, \n",
            "\t0xef, 0xde, 0xcd, 0xd2, 0xfa, 0x18, 0x52, 0x46, 0x3a, 0xbe, 0xed, 0x09, \n",
            "\t0xee, 0x3f, 0x92, 0xe5, 0x23, 0xe5, 0xb8, 0x02, 0xe2, 0x2e, 0xdc, 0xa0, \n",
            "\t0xd5, 0xca, 0xe0, 0xf5, 0x3c, 0xbe, 0x07, 0xd3, 0x09, 0x53, 0xd5, 0xac, \n",
            "\t0x5b, 0x27, 0xeb, 0x41, 0x4f, 0xec, 0x1f, 0xcd, 0xaa, 0xff, 0x20, 0xe4, \n",
            "\t0x0e, 0xba, 0x09, 0xb9, 0xe1, 0x23, 0xd0, 0x3d, 0xd2, 0x9e, 0x20, 0xeb, \n",
            "\t0xd4, 0x26, 0xf4, 0x0e, 0x24, 0x51, 0xf7, 0x3f, 0x05, 0xd7, 0x48, 0xb3, \n",
            "\t0x30, 0x23, 0x41, 0xf5, 0xee, 0x53, 0x06, 0x2a, 0xb6, 0x2a, 0x32, 0x42, \n",
            "\t0x5d, 0x1d, 0x4c, 0x04, 0xd6, 0x30, 0x3a, 0x34, 0xca, 0xa3, 0x3c, 0x24, \n",
            "\t0xc6, 0x56, 0xcb, 0xb9, 0x4f, 0x2d, 0x13, 0xb9, 0xa0, 0x20, 0xc7, 0xc2, \n",
            "\t0x3c, 0xb3, 0xfc, 0x2d, 0xae, 0xb2, 0xf1, 0x2e, 0xe7, 0x24, 0xf4, 0xbb, \n",
            "\t0x38, 0x23, 0x56, 0xe2, 0x53, 0xc4, 0xc2, 0xef, 0x51, 0xf9, 0x24, 0x38, \n",
            "\t0x08, 0xfb, 0x0c, 0x3f, 0xa6, 0x5d, 0xfa, 0xc3, 0x04, 0x34, 0x9f, 0xd6, \n",
            "\t0x2b, 0x43, 0xae, 0x0c, 0xe5, 0x41, 0x1a, 0xe6, 0xe6, 0x38, 0xb2, 0xbd, \n",
            "\t0xc7, 0xff, 0x4b, 0x16, 0xc7, 0xe1, 0x15, 0x33, 0xa4, 0xd9, 0xb9, 0x1c, \n",
            "\t0xd0, 0x36, 0x89, 0xb0, 0x23, 0xd1, 0xc8, 0x45, 0xff, 0x57, 0x52, 0x01, \n",
            "\t0x26, 0xee, 0x10, 0x2c, 0x1d, 0x35, 0x5b, 0x3d, 0x49, 0x9d, 0xa9, 0xb4, \n",
            "\t0xe5, 0x2d, 0x2d, 0x15, 0x9f, 0xc4, 0x02, 0xc1, 0x3e, 0xbc, 0xb1, 0x33, \n",
            "\t0x11, 0xa6, 0x30, 0x39, 0xea, 0x31, 0x05, 0x2c, 0x08, 0x5b, 0xb4, 0x04, \n",
            "\t0xef, 0xdc, 0xdd, 0x1f, 0xf8, 0x43, 0x17, 0x9d, 0x0e, 0xff, 0xfb, 0x97, \n",
            "\t0x52, 0xbe, 0x34, 0xe9, 0xdf, 0x0c, 0x4f, 0x57, 0xb9, 0xe8, 0xe1, 0xaf, \n",
            "\t0xd8, 0xba, 0xc5, 0xd8, 0xbb, 0x1f, 0xe0, 0x13, 0x2c, 0xea, 0x4a, 0xab, \n",
            "\t0x2f, 0xfb, 0xb8, 0xde, 0x05, 0xc2, 0xc5, 0x2c, 0xfb, 0xd2, 0x51, 0xd2, \n",
            "\t0x32, 0xc1, 0x0f, 0xc0, 0xec, 0x36, 0xc8, 0xe2, 0xe6, 0x26, 0xef, 0x56, \n",
            "\t0xe7, 0xa8, 0xce, 0xb8, 0x49, 0x23, 0xed, 0xaa, 0xf6, 0x34, 0x4f, 0xd7, \n",
            "\t0xac, 0x07, 0x0b, 0xf2, 0xcc, 0xdb, 0x56, 0xaa, 0xe0, 0x36, 0xda, 0x10, \n",
            "\t0x53, 0xb6, 0x16, 0x23, 0xac, 0x55, 0xba, 0x3b, 0x15, 0x57, 0xca, 0x4c, \n",
            "\t0xb8, 0x3b, 0x2a, 0xcd, 0xe7, 0xcd, 0x29, 0x40, 0xf3, 0xba, 0x2e, 0x9c, \n",
            "\t0x06, 0x12, 0x97, 0xc4, 0xd7, 0x58, 0xf0, 0xe1, 0x39, 0xfe, 0x52, 0x46, \n",
            "\t0x4a, 0x1f, 0xda, 0x41, 0xb3, 0x2f, 0xbc, 0x0b, 0x28, 0x0d, 0xe4, 0x4e, \n",
            "\t0x2f, 0xa6, 0x3c, 0xe2, 0x46, 0xb6, 0x52, 0x02, 0x03, 0xfb, 0xe9, 0xc3, \n",
            "\t0x21, 0x1a, 0x51, 0xd3, 0xc6, 0x24, 0x48, 0xac, 0x43, 0x9b, 0xf6, 0xc4, \n",
            "\t0x0f, 0x14, 0xde, 0x2d, 0xda, 0x28, 0xc7, 0x4f, 0xcd, 0xb9, 0xa7, 0xd0, \n",
            "\t0x3e, 0x0b, 0x08, 0xb1, 0xf5, 0x2c, 0x29, 0xe4, 0x44, 0xe2, 0xe8, 0xff, \n",
            "\t0xd3, 0x14, 0x19, 0x11, 0x1e, 0x35, 0x2d, 0xd4, 0x07, 0xd4, 0xb9, 0xa5, \n",
            "\t0xdb, 0x1a, 0xd0, 0x42, 0xfd, 0xf4, 0xf1, 0x17, 0xa8, 0x3f, 0xb8, 0x27, \n",
            "\t0xb1, 0x4e, 0x33, 0x30, 0x0a, 0x29, 0xec, 0x3b, 0xe7, 0xa7, 0xfb, 0x39, \n",
            "\t0x47, 0x3e, 0xc5, 0x3e, 0x1b, 0xd5, 0xba, 0xe4, 0x1a, 0x4b, 0x32, 0x08, \n",
            "\t0xb4, 0xed, 0x47, 0x21, 0xe2, 0x8a, 0x57, 0x39, 0x91, 0x19, 0xb4, 0xe0, \n",
            "\t0x2c, 0x43, 0x2c, 0x12, 0xd4, 0xc3, 0x07, 0xe0, 0xc9, 0x30, 0xca, 0x4a, \n",
            "\t0x14, 0xe2, 0x39, 0x08, 0x63, 0x3b, 0x26, 0xd2, 0x0e, 0x3b, 0xf8, 0xcb, \n",
            "\t0xc8, 0xea, 0x04, 0x5f, 0xd4, 0xa2, 0x0f, 0x06, 0x22, 0x27, 0xcc, 0xf7, \n",
            "\t0xe6, 0xf5, 0x44, 0x4a, 0x2f, 0xb9, 0x3b, 0xae, 0xdf, 0xf9, 0xb8, 0xcb, \n",
            "\t0x0a, 0xe7, 0x3c, 0xfd, 0xf1, 0x39, 0x3f, 0x4c, 0x2f, 0xc3, 0x32, 0x11, \n",
            "\t0x44, 0xe0, 0x62, 0xca, 0x45, 0xdf, 0x12, 0x16, 0x54, 0x16, 0xf7, 0x13, \n",
            "\t0x44, 0x1f, 0xe7, 0x00, 0xd1, 0xdc, 0xd2, 0xfd, 0xd1, 0xc6, 0xbd, 0x3e, \n",
            "\t0xd5, 0x24, 0xf7, 0x3a, 0x03, 0x68, 0x2e, 0x21, 0x2f, 0xa6, 0xe4, 0xaa, \n",
            "\t0xaa, 0x21, 0xd1, 0xed, 0x21, 0xdc, 0xb8, 0x2a, 0x2f, 0xad, 0xd8, 0xd3, \n",
            "\t0x01, 0x48, 0x48, 0xa0, 0x16, 0xc1, 0x51, 0x4c, 0x06, 0x49, 0x29, 0xe2, \n",
            "\t0x48, 0x12, 0xb6, 0x0d, 0xb3, 0xb6, 0xc5, 0x02, 0x53, 0x4c, 0x26, 0xfd, \n",
            "\t0x30, 0xfa, 0x40, 0x3c, 0xbf, 0x02, 0x21, 0x4f, 0xf3, 0xc0, 0xc3, 0x9f, \n",
            "\t0xe9, 0x10, 0xad, 0xdd, 0x4a, 0xdd, 0xc0, 0xd7, 0x38, 0xc3, 0xae, 0xf1, \n",
            "\t0xe2, 0x4b, 0x42, 0x6d, 0xcb, 0x4b, 0x21, 0x82, 0x2a, 0xe6, 0xc8, 0x50, \n",
            "\t0xb6, 0xcf, 0xfc, 0x32, 0xf1, 0x19, 0x0b, 0x67, 0xb7, 0x54, 0x5c, 0x35, \n",
            "\t0x53, 0x35, 0xca, 0xfb, 0xf0, 0x3e, 0xd7, 0x22, 0xc4, 0xab, 0x05, 0xd5, \n",
            "\t0xc5, 0xef, 0x39, 0x60, 0xec, 0x3b, 0x44, 0x22, 0xfd, 0x16, 0x0c, 0xb7, \n",
            "\t0x18, 0xef, 0xf0, 0xd2, 0xda, 0xa7, 0xc8, 0x0e, 0xac, 0x16, 0x04, 0xe5, \n",
            "\t0x18, 0x00, 0xcb, 0xad, 0xed, 0xd5, 0x3c, 0xe6, 0x1a, 0x32, 0xa7, 0x0e, \n",
            "\t0xf3, 0x05, 0x5b, 0x23, 0xb2, 0xc9, 0x1f, 0x3c, 0xd8, 0x0a, 0x39, 0xd3, \n",
            "\t0xf6, 0x56, 0x31, 0xd0, 0xee, 0xa8, 0xf4, 0x04, 0x37, 0x1c, 0xc6, 0xce, \n",
            "\t0xde, 0x3f, 0xd1, 0x28, 0x67, 0x09, 0x4f, 0x3b, 0xdd, 0xc5, 0xf3, 0xd8, \n",
            "\t0xd7, 0x25, 0x0d, 0xc5, 0xc4, 0xc1, 0x2c, 0x49, 0xcc, 0xcb, 0x48, 0xbe, \n",
            "\t0xbb, 0x08, 0xb9, 0xf6, 0x1b, 0xd0, 0xd9, 0xf1, 0xfc, 0x26, 0xb7, 0x2c, \n",
            "\t0x2c, 0xc7, 0xd3, 0xaf, 0x0f, 0x02, 0x1c, 0x40, 0xcb, 0xab, 0x29, 0x10, \n",
            "\t0x14, 0xc9, 0x0d, 0xe7, 0xc4, 0xfd, 0x12, 0x22, 0xb6, 0xd6, 0x41, 0xf2, \n",
            "\t0x30, 0x53, 0xe1, 0x4c, 0xd1, 0x3e, 0x0b, 0x57, 0x91, 0x0a, 0xb5, 0xec, \n",
            "\t0xd2, 0xc4, 0xb0, 0xaa, 0xcd, 0x1d, 0xa9, 0xf9, 0x55, 0xe2, 0xed, 0xe7, \n",
            "\t0xdb, 0x07, 0x32, 0xda, 0xa9, 0x32, 0xba, 0xd8, 0xea, 0xcd, 0xb0, 0xff, \n",
            "\t0xf4, 0x31, 0x01, 0x34, 0xdf, 0xea, 0xce, 0x10, 0x29, 0x4b, 0x4e, 0xe2, \n",
            "\t0x8e, 0xb3, 0x16, 0xce, 0xab, 0x40, 0xb5, 0x12, 0xe8, 0x4b, 0xf5, 0x1b, \n",
            "\t0x4f, 0x30, 0xdc, 0xfe, 0x5c, 0xce, 0xad, 0x4f, 0xcb, 0x5d, 0x52, 0xd7, \n",
            "\t0xe9, 0xb8, 0x4c, 0xb0, 0xd4, 0x0c, 0x1b, 0x9c, 0x00, 0x58, 0x14, 0x14, \n",
            "\t0x4b, 0x4c, 0xae, 0xc5, 0xc9, 0xb1, 0x5c, 0x47, 0xfd, 0x00, 0xf7, 0xb3, \n",
            "\t0xaf, 0xcf, 0x11, 0xa9, 0xe8, 0xa2, 0xa6, 0x34, 0x42, 0x24, 0xf1, 0x4c, \n",
            "\t0xa8, 0xb5, 0x46, 0xf8, 0x31, 0xba, 0xfe, 0xe7, 0xde, 0x3d, 0xe5, 0x07, \n",
            "\t0x01, 0xc0, 0x41, 0x82, 0xd2, 0xdc, 0xfb, 0x41, 0xc6, 0xba, 0xef, 0x55, \n",
            "\t0xa5, 0x11, 0x13, 0x2e, 0xf0, 0xd0, 0x5e, 0x59, 0xdc, 0x07, 0xc4, 0xdf, \n",
            "\t0xb5, 0x2e, 0xcf, 0xff, 0xf0, 0x13, 0x2f, 0x4b, 0x35, 0xf5, 0x90, 0xfd, \n",
            "\t0xd2, 0x3e, 0x58, 0xfd, 0xdf, 0xce, 0x46, 0x17, 0x1b, 0xcf, 0xc1, 0x20, \n",
            "\t0x56, 0x2f, 0xc1, 0x25, 0xe8, 0xb3, 0x45, 0x38, 0x06, 0xb0, 0xa1, 0xc8, \n",
            "\t0x4a, 0xfa, 0xb5, 0x55, 0xe1, 0xff, 0x1e, 0x2a, 0xab, 0xcc, 0xbb, 0xbb, \n",
            "\t0x9f, 0xb0, 0xf9, 0x1d, 0x52, 0x3a, 0xdb, 0xc7, 0x1b, 0x40, 0x20, 0xf7, \n",
            "\t0xd9, 0xdb, 0xdb, 0xed, 0xb7, 0xd1, 0xf1, 0x45, 0xe8, 0xdf, 0xf3, 0x04, \n",
            "\t0x1b, 0x56, 0xbf, 0xad, 0x1e, 0x12, 0xc9, 0x0d, 0xe4, 0x45, 0xc5, 0xb3, \n",
            "\t0x16, 0xbf, 0x38, 0xce, 0xfc, 0x54, 0xae, 0xb3, 0xc9, 0x2b, 0x5d, 0x32, \n",
            "\t0x28, 0xc8, 0x30, 0x48, 0x09, 0x43, 0x2b, 0x0d, 0xd5, 0xdc, 0xbf, 0x3c, \n",
            "\t0xb2, 0xaa, 0xfa, 0x1b, 0xf2, 0xac, 0xcf, 0xbc, 0x12, 0xce, 0x9d, 0xc0, \n",
            "\t0x31, 0x35, 0xe3, 0x13, 0x07, 0xd5, 0x96, 0x5a, 0x21, 0xd2, 0x02, 0x01, \n",
            "\t0x1a, 0x43, 0xcb, 0x8d, 0xd5, 0xad, 0x43, 0x23, 0xac, 0x54, 0x0e, 0x31, \n",
            "\t0x35, 0x38, 0xaa, 0x9e, 0xb9, 0xe0, 0xc9, 0xeb, 0xd5, 0xc6, 0xdc, 0xb9, \n",
            "\t0x55, 0x8c, 0x43, 0x22, 0x31, 0x4b, 0x1d, 0xc2, 0x54, 0xf2, 0x1c, 0xff, \n",
            "\t0xdb, 0x04, 0x56, 0xd5, 0x1c, 0xb0, 0x23, 0xba, 0x4b, 0xaa, 0x93, 0xaa, \n",
            "\t0x44, 0xf3, 0x18, 0xcb, 0xd7, 0x1b, 0xeb, 0xe1, 0xe0, 0xa3, 0x31, 0xf7, \n",
            "\t0x05, 0x6a, 0x1d, 0xf7, 0x0b, 0x56, 0xb7, 0xeb, 0xe3, 0xfc, 0x27, 0x4f, \n",
            "\t0x15, 0xd3, 0xad, 0x24, 0x4d, 0x04, 0xde, 0xc6, 0xcf, 0xc7, 0x3c, 0xe1, \n",
            "\t0x8d, 0xad, 0xd5, 0x0c, 0x0e, 0x64, 0xe2, 0xd1, 0x2c, 0xe7, 0x54, 0xff, \n",
            "\t0x00, 0xeb, 0x25, 0x0c, 0xd7, 0x56, 0x4d, 0xc4, 0xfb, 0xc9, 0xc6, 0x0c, \n",
            "\t0x29, 0x56, 0x43, 0xca, 0xeb, 0x11, 0x00, 0xae, 0x05, 0x40, 0xe9, 0xf9, \n",
            "\t0x27, 0x09, 0xd5, 0x0a, 0xb4, 0x07, 0x39, 0x52, 0x19, 0xb6, 0x41, 0x3f, \n",
            "\t0x36, 0xa3, 0x1e, 0x56, 0xa3, 0x39, 0xb9, 0xf4, 0x58, 0x2f, 0x4b, 0x05, \n",
            "\t0xd3, 0xbc, 0x09, 0xf2, 0x30, 0x0b, 0xd9, 0x21, 0x37, 0x53, 0x1d, 0x1f, \n",
            "\t0xd5, 0xad, 0xba, 0x57, 0xaa, 0x41, 0x38, 0x47, 0x4a, 0xe2, 0x2b, 0x56, \n",
            "\t0xf6, 0xf4, 0xe0, 0x2f, 0x16, 0xa5, 0x3b, 0xaf, 0x33, 0x23, 0x04, 0xe7, \n",
            "\t0x1c, 0x29, 0x0d, 0x33, 0x0f, 0x1f, 0x25, 0x17, 0xdd, 0xc6, 0x2c, 0x05, \n",
            "\t0xb9, 0xe0, 0xf9, 0x0d, 0x5b, 0xe7, 0x03, 0xd1, 0x5a, 0xd1, 0xcd, 0x48, \n",
            "\t0x2d, 0xa7, 0xcd, 0xa6, 0xf5, 0xd7, 0x1a, 0x4c, 0xd8, 0x09, 0xb8, 0x07, \n",
            "\t0x36, 0x54, 0x33, 0xad, 0x44, 0xc4, 0x50, 0xb0, 0x41, 0xc1, 0x08, 0x18, \n",
            "\t0xd9, 0xd4, 0xcc, 0x33, 0xc8, 0xb4, 0xe9, 0xf1, 0x05, 0xe5, 0xc1, 0x38, \n",
            "\t0xc9, 0xdd, 0x45, 0x42, 0xd9, 0x28, 0x6e, 0xf6, 0x2c, 0xca, 0xa9, 0xdf, \n",
            "\t0x09, 0xc3, 0xfa, 0xce, 0xe8, 0x27, 0x0e, 0x1c, 0x52, 0xc0, 0x41, 0x48, \n",
            "\t0xce, 0xd1, 0x5c, 0xe2, 0x0e, 0x4c, 0x3b, 0x56, 0x0d, 0x37, 0xed, 0xd0, \n",
            "\t0xa3, 0xd2, 0x48, 0xce, 0xd7, 0xcc, 0x32, 0xc4, 0x19, 0x0d, 0xd3, 0xf6, \n",
            "\t0xc4, 0x50, 0xd6, 0x50, 0x38, 0x0b, 0xe1, 0xa5, 0x37, 0x2e, 0xcb, 0xd7, \n",
            "\t0xe2, 0xf9, 0xf6, 0xec, 0x3d, 0xce, 0x3c, 0xfe, 0x29, 0xc2, 0x3d, 0xe1, \n",
            "\t0x33, 0x0f, 0xb3, 0x05, 0xc4, 0x9f, 0xf8, 0x4b, 0xf1, 0x2b, 0x45, 0x09, \n",
            "\t0xb7, 0x2b, 0xb4, 0xf0, 0xdd, 0xc9, 0xb2, 0x54, 0xd7, 0x14, 0x4a, 0x45, \n",
            "\t0x3f, 0xa6, 0xb1, 0xda, 0x49, 0x45, 0x35, 0x56, 0xfc, 0xe6, 0x17, 0xd1, \n",
            "\t0xcb, 0x2d, 0x0f, 0xb4, 0x04, 0xd3, 0x11, 0xef, 0xc0, 0x1d, 0xef, 0x4c, \n",
            "\t0x41, 0x2f, 0x0c, 0xfd, 0xf4, 0x9c, 0x97, 0xe7, 0xca, 0xca, 0xd1, 0xb5, \n",
            "\t0xaf, 0x2b, 0x39, 0x2a, 0xce, 0xfa, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x02, 0x00, 0x00, 0x2d, 0x7c, 0x0d, 0xbe, 0x3f, 0x4e, 0x49, 0xbe, \n",
            "\t0x07, 0x26, 0x2f, 0xbe, 0x89, 0x47, 0x85, 0xbd, 0x41, 0xa4, 0x86, 0x3e, \n",
            "\t0xc2, 0x55, 0xec, 0x3d, 0xb5, 0xbd, 0x97, 0xbe, 0xf4, 0x86, 0x2b, 0xbe, \n",
            "\t0xff, 0x26, 0x07, 0xbc, 0x94, 0x15, 0x04, 0x3e, 0x9f, 0xc5, 0x81, 0xbe, \n",
            "\t0x76, 0x4b, 0x04, 0x3e, 0xe6, 0xd4, 0x00, 0x3e, 0x78, 0x19, 0x06, 0x3e, \n",
            "\t0xf3, 0x37, 0x3b, 0x3e, 0x38, 0xb7, 0x8a, 0xbd, 0x0d, 0x6c, 0xcb, 0xbd, \n",
            "\t0xba, 0xe2, 0xdb, 0x3d, 0xe7, 0x31, 0x65, 0xbe, 0xad, 0x6f, 0x14, 0x3e, \n",
            "\t0x1f, 0x47, 0xb0, 0xbe, 0x5b, 0xb8, 0x96, 0xbc, 0xdc, 0xd7, 0x23, 0xbe, \n",
            "\t0x5a, 0x5b, 0x32, 0x3e, 0x69, 0x1b, 0x89, 0x3e, 0xb4, 0xf3, 0x58, 0xbe, \n",
            "\t0x6b, 0x71, 0x23, 0x3e, 0xc3, 0x79, 0x68, 0xbe, 0x1d, 0xe5, 0x9b, 0x3e, \n",
            "\t0x9c, 0xfc, 0x1b, 0x3e, 0xc8, 0x68, 0x52, 0x3e, 0x9c, 0xfb, 0xe7, 0xbd, \n",
            "\t0xe7, 0x69, 0x28, 0xbe, 0x6c, 0x91, 0x24, 0x3e, 0xfa, 0x26, 0x85, 0xbe, \n",
            "\t0xc0, 0xe4, 0xb7, 0x3d, 0xce, 0x78, 0x24, 0x3e, 0x49, 0xc7, 0x2f, 0x3e, \n",
            "\t0x0a, 0xfc, 0x43, 0xbe, 0x24, 0x8f, 0x89, 0x3e, 0xcc, 0x74, 0x1e, 0x3d, \n",
            "\t0x92, 0x72, 0x88, 0x3e, 0x68, 0x7d, 0x5c, 0x3c, 0xb3, 0x6c, 0x91, 0xbd, \n",
            "\t0xf8, 0x2b, 0x9a, 0xbe, 0x70, 0x30, 0xc1, 0xbd, 0xd9, 0xf5, 0x74, 0xbe, \n",
            "\t0xc4, 0x1f, 0x99, 0x3e, 0xb3, 0x71, 0x84, 0xbe, 0xe8, 0x19, 0x84, 0xbe, \n",
            "\t0x24, 0x85, 0xb8, 0x3d, 0x85, 0xf3, 0x0d, 0xbe, 0x81, 0x91, 0x3f, 0xbd, \n",
            "\t0x9a, 0xf6, 0x5e, 0x3e, 0x1a, 0xc1, 0x69, 0x3e, 0x32, 0xe4, 0x1b, 0xbe, \n",
            "\t0x3f, 0xcd, 0x63, 0x3e, 0xd0, 0x80, 0x68, 0xbe, 0x6c, 0xd4, 0x1b, 0xbe, \n",
            "\t0x86, 0x3d, 0x6c, 0x3e, 0x1e, 0x15, 0x25, 0xbe, 0x59, 0x73, 0xb8, 0x3d, \n",
            "\t0x95, 0xe0, 0x1c, 0x3d, 0x7c, 0xfb, 0x0f, 0x3e, 0x4a, 0x81, 0x31, 0xbb, \n",
            "\t0x57, 0xe9, 0x1e, 0x3e, 0x70, 0x69, 0x60, 0x3e, 0x56, 0x52, 0x81, 0xbc, \n",
            "\t0xab, 0xe1, 0x7f, 0x3e, 0x65, 0x13, 0xa9, 0x3e, 0x05, 0xcf, 0xad, 0x3d, \n",
            "\t0x08, 0x9c, 0xad, 0x3e, 0x5e, 0x1f, 0xbf, 0xbd, 0x40, 0x94, 0x5c, 0xbe, \n",
            "\t0x76, 0xbe, 0x8a, 0x3e, 0xb0, 0xc3, 0xce, 0xbd, 0xbe, 0xb8, 0x01, 0xbe, \n",
            "\t0x4b, 0xc3, 0x92, 0x3d, 0x2e, 0xf5, 0x5e, 0xbd, 0xc4, 0xca, 0x76, 0xbd, \n",
            "\t0x3a, 0xc9, 0x92, 0x3e, 0x41, 0xc4, 0x41, 0x3e, 0xa6, 0x8a, 0x9f, 0x3d, \n",
            "\t0x8f, 0x7a, 0xa7, 0xbe, 0xac, 0x71, 0x23, 0xbe, 0x80, 0xf9, 0xd9, 0x3d, \n",
            "\t0xb8, 0x2b, 0x4c, 0x3e, 0x00, 0x4c, 0x8f, 0x3e, 0xea, 0x84, 0x8f, 0xbe, \n",
            "\t0x03, 0x04, 0x7d, 0xbe, 0x85, 0x40, 0x01, 0x3d, 0x8e, 0xad, 0x3c, 0xbe, \n",
            "\t0x11, 0x99, 0x5a, 0x3e, 0xf7, 0xcb, 0x9b, 0x3e, 0x49, 0xaf, 0x7b, 0xbd, \n",
            "\t0x9f, 0xe8, 0x19, 0xbc, 0xd0, 0x4b, 0x48, 0x3e, 0x67, 0x1b, 0xec, 0xbd, \n",
            "\t0xe5, 0xf3, 0xb8, 0xbe, 0xa4, 0xac, 0xa0, 0xbd, 0x12, 0x16, 0x8f, 0x3d, \n",
            "\t0xa1, 0xe9, 0x9a, 0x3d, 0xb5, 0x57, 0x8a, 0xbe, 0x13, 0x31, 0x34, 0xbe, \n",
            "\t0x14, 0xb6, 0xff, 0x3c, 0x46, 0x16, 0xac, 0xbe, 0xfa, 0xcb, 0x08, 0x3e, \n",
            "\t0xb4, 0xf7, 0x64, 0x3e, 0x6c, 0xda, 0xe1, 0x3d, 0x42, 0x52, 0xb4, 0xbe, \n",
            "\t0x96, 0x34, 0xfd, 0x3d, 0x30, 0xc1, 0xf9, 0xbd, 0x7e, 0xa4, 0x30, 0xbe, \n",
            "\t0x2d, 0x77, 0x04, 0x3d, 0xef, 0xc4, 0x3a, 0xbe, 0x01, 0x31, 0x11, 0xbe, \n",
            "\t0x51, 0x9d, 0xc6, 0x3e, 0x18, 0xba, 0x93, 0xbc, 0x1c, 0x33, 0x54, 0xbe, \n",
            "\t0x6c, 0xdd, 0xc4, 0xbd, 0x12, 0x01, 0x91, 0x3c, 0xbe, 0xfc, 0xb9, 0x3c, \n",
            "\t0xb9, 0x46, 0x18, 0xbd, 0x5a, 0xd3, 0x0b, 0xbe, 0xed, 0x07, 0x9b, 0x3e, \n",
            "\t0x31, 0x71, 0x67, 0x3e, 0x15, 0x89, 0x48, 0xbe, 0x34, 0x01, 0xde, 0x3d, \n",
            "\t0xda, 0xfc, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x80, 0x01, 0x00, 0x00, \n",
            "\t0xd4, 0x92, 0x9e, 0x3d, 0x75, 0x9f, 0xa6, 0x3e, 0xe2, 0x06, 0xa4, 0x3e, \n",
            "\t0x82, 0xfd, 0xdc, 0xbe, 0xe9, 0xae, 0x8c, 0xbd, 0xe3, 0x8f, 0x9f, 0x3e, \n",
            "\t0x39, 0x87, 0xac, 0x3e, 0xd4, 0xf9, 0x93, 0x3e, 0x16, 0x6e, 0xbf, 0xbe, \n",
            "\t0x36, 0x1c, 0xd7, 0xbd, 0x3f, 0x95, 0xa4, 0x3e, 0x62, 0x42, 0x37, 0x3e, \n",
            "\t0x9d, 0x1f, 0x89, 0xbe, 0x45, 0xc0, 0x79, 0x3e, 0x89, 0xe0, 0xf6, 0xbd, \n",
            "\t0x21, 0x5e, 0xaf, 0x3e, 0x07, 0x56, 0x35, 0xbe, 0x8b, 0x62, 0x49, 0x3e, \n",
            "\t0xa3, 0xd4, 0xda, 0x3e, 0x6a, 0xf3, 0x70, 0x3d, 0x1d, 0xc1, 0xc9, 0xbc, \n",
            "\t0x12, 0x5e, 0x09, 0x3e, 0xd4, 0x80, 0x06, 0x3e, 0x05, 0x17, 0x77, 0xbc, \n",
            "\t0xa7, 0x78, 0xe6, 0xbd, 0x6c, 0x3e, 0xb0, 0x3e, 0x30, 0x8a, 0x0f, 0x3e, \n",
            "\t0xa0, 0x76, 0xa4, 0x3a, 0x0d, 0x21, 0x64, 0x3e, 0xa9, 0x44, 0x35, 0x3e, \n",
            "\t0x82, 0xe0, 0x70, 0x3e, 0x95, 0xf3, 0x39, 0x3e, 0x96, 0x70, 0x8c, 0x3d, \n",
            "\t0x1d, 0xb7, 0xdd, 0xbd, 0x84, 0x4b, 0x53, 0xbd, 0x74, 0xb3, 0xc4, 0xbe, \n",
            "\t0xa2, 0x1f, 0xdc, 0xbc, 0x49, 0x69, 0x79, 0x3e, 0x80, 0x04, 0x17, 0xbe, \n",
            "\t0xa3, 0x72, 0x75, 0x3e, 0x60, 0xdc, 0xd2, 0xbd, 0x55, 0x9d, 0x80, 0xbe, \n",
            "\t0x05, 0xb5, 0xa1, 0x3e, 0x4d, 0xea, 0x69, 0xbe, 0x69, 0x76, 0xa5, 0x3d, \n",
            "\t0x81, 0x12, 0x01, 0x3d, 0x87, 0xe3, 0x8a, 0x3e, 0x67, 0xad, 0xcf, 0x3b, \n",
            "\t0x39, 0x9d, 0x8e, 0x3e, 0xb1, 0x85, 0x95, 0x3c, 0xda, 0xaf, 0xaf, 0x3d, \n",
            "\t0x74, 0x97, 0xb6, 0xbe, 0x32, 0x67, 0xed, 0x3d, 0xc9, 0xb1, 0x82, 0xbd, \n",
            "\t0x45, 0x3e, 0x94, 0xbe, 0xea, 0x1c, 0xc5, 0x3e, 0x8a, 0x0d, 0x89, 0x3e, \n",
            "\t0x10, 0x26, 0x89, 0xbe, 0x86, 0x41, 0xac, 0xbe, 0x5d, 0x10, 0x94, 0x3d, \n",
            "\t0x26, 0x20, 0x28, 0x3e, 0x36, 0x37, 0xd0, 0x3e, 0x19, 0xb5, 0xbe, 0x3e, \n",
            "\t0x8e, 0x5a, 0x05, 0x3e, 0xd9, 0xcd, 0xbb, 0xbe, 0x19, 0xb2, 0xa8, 0x3e, \n",
            "\t0x1a, 0x41, 0xb3, 0xbe, 0x23, 0x2f, 0xc3, 0xbe, 0x85, 0xdc, 0xbb, 0xbd, \n",
            "\t0xf6, 0xa5, 0xd5, 0xbc, 0xb6, 0xbc, 0xf4, 0xbe, 0x73, 0x0f, 0x28, 0x3e, \n",
            "\t0xf5, 0x03, 0x33, 0xbd, 0xa5, 0x2b, 0xae, 0xbd, 0xa4, 0x8d, 0xcf, 0x3e, \n",
            "\t0x60, 0xc9, 0xb3, 0xbe, 0x73, 0xae, 0xeb, 0xbd, 0xb4, 0xcd, 0x90, 0x3e, \n",
            "\t0x85, 0xfc, 0xc1, 0xbd, 0x2e, 0x27, 0x46, 0xbe, 0x78, 0x8a, 0xb6, 0x3d, \n",
            "\t0x0e, 0xf0, 0x45, 0xbe, 0x47, 0x10, 0xd6, 0xbe, 0x30, 0xde, 0xa7, 0x3e, \n",
            "\t0xca, 0x71, 0xe8, 0xbe, 0xbd, 0x63, 0x24, 0x3e, 0xa6, 0x52, 0xd0, 0xbe, \n",
            "\t0xe6, 0x31, 0xc4, 0xbe, 0xd0, 0xb6, 0xd4, 0x3e, 0xb7, 0x09, 0x3d, 0xbe, \n",
            "\t0x99, 0xd6, 0x85, 0x3d, 0xb1, 0xea, 0x7a, 0xbe, 0x5a, 0xc8, 0x85, 0xbe, \n",
            "\t0x71, 0x2a, 0x5f, 0x3c, 0xff, 0xd5, 0x0b, 0xbe, 0x72, 0x01, 0x7e, 0xbd, \n",
            "\t0x66, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00, \n",
            "\t0x9c, 0x1d, 0x39, 0x3d, 0x11, 0xc1, 0x92, 0xbc, 0xf6, 0xbb, 0xb6, 0x3c, \n",
            "\t0x6e, 0x21, 0x1c, 0x3c, 0xb5, 0xdb, 0x73, 0xbc, 0xfa, 0x08, 0x5f, 0x3c, \n",
            "\t0xdc, 0xed, 0x4b, 0x3b, 0x13, 0x27, 0x32, 0xbd, 0x7d, 0xcf, 0x45, 0xbc, \n",
            "\t0xea, 0xa1, 0x56, 0x3c, 0x43, 0x9c, 0xc7, 0x3c, 0xe2, 0xec, 0x1f, 0xbc, \n",
            "\t0x3a, 0x65, 0x78, 0xbc, 0xba, 0x41, 0x16, 0x3c, 0x53, 0x55, 0x38, 0x3c, \n",
            "\t0xf9, 0xc8, 0x13, 0x3b, 0x6a, 0x37, 0xd4, 0xbc, 0x46, 0x5a, 0xba, 0x3b, \n",
            "\t0x14, 0x58, 0x3d, 0x3d, 0x6d, 0xc3, 0x37, 0x3c, 0x79, 0x38, 0x8b, 0x3c, \n",
            "\t0x96, 0xc0, 0x2d, 0x3d, 0x7c, 0xbd, 0x9c, 0xbb, 0x87, 0x33, 0x81, 0x3c, \n",
            "\t0x16, 0x7f, 0x4a, 0x3a, 0x77, 0x26, 0x80, 0x3c, 0xa0, 0xb8, 0xe3, 0x3c, \n",
            "\t0xcd, 0xe9, 0xf1, 0xba, 0x40, 0xe8, 0x84, 0x3a, 0x13, 0x2c, 0xd0, 0xbb, \n",
            "\t0xfa, 0xb7, 0x07, 0xbc, 0x18, 0x63, 0x4f, 0xbb, 0xf2, 0xfe, 0xff, 0xff, \n",
            "\t0x04, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0xd3, 0x62, 0x4f, 0xbc, \n",
            "\t0xcc, 0xaa, 0x74, 0x3c, 0x78, 0xa0, 0x98, 0x3a, 0x3f, 0x84, 0x97, 0xbc, \n",
            "\t0xb0, 0x76, 0x99, 0x3c, 0xa6, 0x88, 0x03, 0x3d, 0xf3, 0x26, 0x08, 0xbc, \n",
            "\t0xf1, 0xde, 0xe4, 0x3c, 0x21, 0xc9, 0xf0, 0xbc, 0xe4, 0x2b, 0xb5, 0x3a, \n",
            "\t0x86, 0x3e, 0xa7, 0x3b, 0x13, 0x87, 0x96, 0x3b, 0xaf, 0x5d, 0x4f, 0xbc, \n",
            "\t0x3c, 0x21, 0x0e, 0x3d, 0x92, 0x61, 0xb3, 0x3c, 0x00, 0x00, 0x00, 0x00, \n",
            "\t0x14, 0x1b, 0x14, 0x3d, 0xa1, 0xa6, 0xa4, 0x3c, 0x62, 0xe8, 0x52, 0xbc, \n",
            "\t0x51, 0x5c, 0x07, 0x3b, 0xf7, 0xec, 0x08, 0xbc, 0xa5, 0xd4, 0x8c, 0xbc, \n",
            "\t0xb1, 0x37, 0x2a, 0x3c, 0x36, 0xac, 0x49, 0x3d, 0x3e, 0xc8, 0xd6, 0x3c, \n",
            "\t0x71, 0xbe, 0x25, 0xbc, 0xd7, 0xab, 0x56, 0x3c, 0x00, 0x00, 0x00, 0x00, \n",
            "\t0xae, 0x6f, 0x71, 0x3b, 0x88, 0x5f, 0x82, 0x3d, 0xe9, 0xb2, 0xdd, 0x3c, \n",
            "\t0x52, 0x82, 0xc8, 0xbc, 0xef, 0xb2, 0xc9, 0xbc, 0xe6, 0xf9, 0xb7, 0x3b, \n",
            "\t0xce, 0x85, 0x0b, 0x3d, 0xee, 0x6a, 0x92, 0x3c, 0x21, 0x65, 0x26, 0x3d, \n",
            "\t0xe3, 0x9a, 0x1a, 0x3d, 0x40, 0x46, 0x22, 0xbd, 0x48, 0xba, 0x86, 0x3c, \n",
            "\t0x02, 0xd4, 0xfa, 0x3c, 0xa4, 0x5e, 0xa6, 0x3a, 0xca, 0xe5, 0x27, 0xbc, \n",
            "\t0x48, 0xc7, 0xa7, 0x3c, 0x00, 0x00, 0x00, 0x00, 0x0e, 0xf1, 0x5c, 0xbb, \n",
            "\t0xc6, 0x26, 0x91, 0xbc, 0x1b, 0x93, 0x02, 0x3c, 0x10, 0x2d, 0x09, 0xbc, \n",
            "\t0x4b, 0x90, 0x4d, 0xbd, 0x00, 0x00, 0x00, 0x00, 0xeb, 0x0f, 0x07, 0xbd, \n",
            "\t0x0d, 0x84, 0x12, 0x3d, 0x7c, 0x3d, 0xf3, 0x3b, 0xaf, 0xed, 0x46, 0x3c, \n",
            "\t0x8f, 0xf9, 0x1f, 0xbc, 0xb7, 0x1e, 0xb1, 0x3c, 0xd3, 0xb4, 0x20, 0xbd, \n",
            "\t0x81, 0x89, 0x08, 0x3b, 0x4b, 0x1f, 0x40, 0x3c, 0x4c, 0x89, 0x1c, 0x3d, \n",
            "\t0x8d, 0x84, 0xb2, 0xbc, 0xf9, 0xa2, 0x18, 0xbc, 0x76, 0xff, 0xc7, 0xbb, \n",
            "\t0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, \n",
            "\t0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x9a, 0x52, 0xbf, 0x3c, \n",
            "\t0x9b, 0x88, 0x32, 0x3c, 0xf0, 0xfa, 0xff, 0xff, 0xf4, 0xfa, 0xff, 0xff, \n",
            "\t0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52, 0x20, 0x43, 0x6f, 0x6e, \n",
            "\t0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x14, 0x00, \n",
            "\t0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00, \n",
            "\t0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0xe8, 0x00, 0x00, 0x00, \n",
            "\t0xec, 0x00, 0x00, 0x00, 0xf0, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, \n",
            "\t0x90, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x8a, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, \n",
            "\t0x10, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x7a, 0xff, 0xff, 0xff, \n",
            "\t0x00, 0x00, 0x00, 0x01, 0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, \n",
            "\t0x03, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0xbe, 0xff, 0xff, 0xff, 0x1c, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x00, 0x08, 0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, \n",
            "\t0x0c, 0x00, 0x08, 0x00, 0x07, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, \n",
            "\t0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x01, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0x08, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, \n",
            "\t0x06, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, \n",
            "\t0x16, 0x00, 0x00, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00, \n",
            "\t0x0e, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, \n",
            "\t0x18, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, \n",
            "\t0x08, 0x00, 0x07, 0x00, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0xb0, 0x03, 0x00, 0x00, \n",
            "\t0x48, 0x03, 0x00, 0x00, 0xe4, 0x02, 0x00, 0x00, 0x90, 0x02, 0x00, 0x00, \n",
            "\t0x48, 0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x8c, 0x01, 0x00, 0x00, \n",
            "\t0xec, 0x00, 0x00, 0x00, 0x5c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x8c, 0xfc, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, \n",
            "\t0x1c, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x34, 0x00, 0x00, 0x00, \n",
            "\t0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x02, 0x00, 0x00, 0x00, \n",
            "\t0x78, 0xfc, 0xff, 0xff, 0x19, 0x00, 0x00, 0x00, 0x53, 0x74, 0x61, 0x74, \n",
            "\t0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, \n",
            "\t0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x3a, 0x30, 0x00, 0x00, 0x00, \n",
            "\t0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, \n",
            "\t0xe0, 0xfc, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, \n",
            "\t0x1c, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00, \n",
            "\t0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x40, 0x00, 0x00, 0x00, \n",
            "\t0xcc, 0xfc, 0xff, 0xff, 0x52, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, \n",
            "\t0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, \n",
            "\t0x73, 0x65, 0x5f, 0x38, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, \n",
            "\t0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x33, \n",
            "\t0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x38, 0x2f, 0x52, 0x65, 0x6c, \n",
            "\t0x75, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, \n",
            "\t0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x38, 0x2f, 0x42, \n",
            "\t0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x6c, 0xfd, 0xff, 0xff, \n",
            "\t0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, \n",
            "\t0x08, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, \n",
            "\t0xff, 0xff, 0xff, 0xff, 0x20, 0x00, 0x00, 0x00, 0x58, 0xfd, 0xff, 0xff, \n",
            "\t0x52, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, \n",
            "\t0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x37, \n",
            "\t0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71, 0x75, \n",
            "\t0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, \n",
            "\t0x73, 0x65, 0x5f, 0x37, 0x2f, 0x52, 0x65, 0x6c, 0x75, 0x3b, 0x73, 0x65, \n",
            "\t0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, \n",
            "\t0x65, 0x6e, 0x73, 0x65, 0x5f, 0x37, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, \n",
            "\t0x64, 0x64, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0x20, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x14, 0x00, \n",
            "\t0x13, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00, \n",
            "\t0x20, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x00, 0x09, 0x50, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x0c, 0x00, \n",
            "\t0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, \n",
            "\t0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0xe4, 0x60, 0x35, 0x3b, 0x1b, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, \n",
            "\t0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, \n",
            "\t0x73, 0x65, 0x5f, 0x38, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00, \n",
            "\t0x02, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, \n",
            "\t0xd6, 0xfe, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, \n",
            "\t0x06, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x54, 0xfe, 0xff, 0xff, \n",
            "\t0x1b, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, \n",
            "\t0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x39, \n",
            "\t0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00, 0x02, 0x00, 0x00, 0x00, \n",
            "\t0x02, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x1a, 0xff, 0xff, 0xff, \n",
            "\t0x10, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, \n",
            "\t0x28, 0x00, 0x00, 0x00, 0x98, 0xfe, 0xff, 0xff, 0x1b, 0x00, 0x00, 0x00, \n",
            "\t0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x33, \n",
            "\t0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x37, 0x2f, 0x4d, 0x61, 0x74, \n",
            "\t0x4d, 0x75, 0x6c, 0x00, 0x02, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, \n",
            "\t0x03, 0x00, 0x00, 0x00, 0x5e, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, \n",
            "\t0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00, \n",
            "\t0xdc, 0xfe, 0xff, 0xff, 0x2b, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, \n",
            "\t0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, \n",
            "\t0x73, 0x65, 0x5f, 0x37, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64, \n",
            "\t0x2f, 0x52, 0x65, 0x61, 0x64, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, \n",
            "\t0x65, 0x4f, 0x70, 0x00, 0x01, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, \n",
            "\t0xae, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, \n",
            "\t0x03, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00, 0x2c, 0xff, 0xff, 0xff, \n",
            "\t0x2b, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, \n",
            "\t0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x38, \n",
            "\t0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, \n",
            "\t0x64, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x00, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, \n",
            "\t0x14, 0x00, 0x10, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, \n",
            "\t0x0e, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, \n",
            "\t0x02, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00, 0x8c, 0xff, 0xff, 0xff, \n",
            "\t0x2b, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, \n",
            "\t0x61, 0x6c, 0x5f, 0x33, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x39, \n",
            "\t0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, \n",
            "\t0x64, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x00, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x14, 0x00, 0x18, 0x00, \n",
            "\t0x14, 0x00, 0x00, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x00, 0x00, \n",
            "\t0x00, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, \n",
            "\t0x20, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, \n",
            "\t0x3c, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, \n",
            "\t0x03, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00, 0x04, 0x00, 0x00, 0x00, \n",
            "\t0x1f, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x5f, \n",
            "\t0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f, 0x64, 0x65, 0x6e, 0x73, \n",
            "\t0x65, 0x5f, 0x37, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x3a, 0x30, 0x00, \n",
            "\t0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, \n",
            "\t0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x10, 0x00, \n",
            "\t0x0f, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, \n",
            "\t0x09, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09\n",
            "};\n",
            "const int model_data_len = 5280;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model) #create a converter\n",
        "tflite_model = converter.convert() \n",
        "\n",
        "open(\"/content/tflite_model.tflite\",\"wb\").write(tflite_model) #Create a file containing our tflite model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1anVX87AoOx6",
        "outputId": "20bce810-1892-4d07-daeb-6e04a35d69dd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11340"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -qq xxd #the tool is installed\n",
        "!echo \"const unsigned char model[] = {\" > /content/tflite_model.h\n",
        "!cat /content/tflite_model.tflite | xxd -i >> /content/model.h #create an hexadecimal array containing all our parameters\n",
        "!echo \"};\" >> /content/model.h\n",
        "from google.colab import files \n",
        "files.download(\"/content/model.h\") # download our file automaticaly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4qTjBumPvkkC",
        "outputId": "dfea9016-ca14-47bb-d61e-0fa70184a702"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eaf14bc2-87bb-477d-a48e-b9fb2ccba3d4\", \"model.h\", 69932)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}